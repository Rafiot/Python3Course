{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting point: end of day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "def entries_counter(source_file):\n",
    "    matches = re.findall('^$', open(source_file, 'r').read(), flags=re.MULTILINE)\n",
    "    nb_blocks = len(matches)\n",
    "    logging.debug(f'{nb_blocks} blocks in the file \"{source_file}\".')\n",
    "    return nb_blocks\n",
    "\n",
    "def file_splitter(source_file_name, number_of_files, separator='\\n', output_name='split'):\n",
    "    logging.info(f'Start to split \"{source_file_name}\" in {number_of_files} files.')\n",
    "    total_blocs_in_file = entries_counter(source_file=source_file_name)\n",
    "    max_blocs_in_file = round(total_blocs_in_file/float(number_of_files), 0)\n",
    "    logging.debug(f'{max_blocs_in_file} blocks per file.')\n",
    "    \n",
    "    padding_length = len(str(number_of_files))\n",
    "    \n",
    "    with open(source_file_name, 'r') as original_file:\n",
    "        file_number = 1\n",
    "        blocs_in_file = 0\n",
    "        new_file_content = ''\n",
    "\n",
    "        # Loop through the file, line by line\n",
    "        for line in original_file:\n",
    "            # Store the line in a temporary variable\n",
    "            new_file_content += line\n",
    "            if line == separator:\n",
    "                # Count the blocks\n",
    "                blocs_in_file += 1\n",
    "            if blocs_in_file > max_blocs_in_file:\n",
    "                logging.debug(f'Writing {output_name}_{file_number:0{padding_length}}.txt.')\n",
    "                # If we reach the limit, write the content of the temporary variable in the new file\n",
    "                with open(f'{output_name}_{file_number:0{padding_length}}.txt', 'w') as new_file:\n",
    "                    new_file.write(new_file_content)\n",
    "                # Reset counters\n",
    "                file_number += 1\n",
    "                blocs_in_file = 0\n",
    "                new_file_content = ''\n",
    "        else:\n",
    "            logging.debug(f'Writing {output_name}_{file_number:0{padding_length}}.txt.')\n",
    "            # EOF reached, writing everything we have in the temporary variable\n",
    "            with open(f'{output_name}_{file_number:0{padding_length}}.txt', 'w') as new_file:\n",
    "                new_file.write(new_file_content)\n",
    "    logging.info(f'Done with \"{source_file_name}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=100, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2fb572b7afc2bdebc639e04db86b437236107ecb7d2442d9feae593dedb5ebca\n",
      "2fb572b7afc2bdebc639e04db86b437236107ecb7d2442d9feae593dedb5ebca\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "\n",
    "with open('data/bview.20030809.1600.txt', 'rb') as f:\n",
    "    hash_source = hashlib.sha256(f.read()).hexdigest()\n",
    "print(hash_source)\n",
    "\n",
    "hash_dest = hashlib.sha256()\n",
    "for out_file in sorted(glob.glob('split_*.txt')):\n",
    "    with open(out_file, 'rb') as f:\n",
    "        hash_dest.update(f.read())\n",
    "dest = hash_dest.hexdigest()\n",
    "print(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install line-profiler memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%prun file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%prun file_splitter(source_file_name='data/bview.20180216.0800.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 143.39 MiB, increment: 96.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1\n",
    "\n",
    "Let's think a bit how we can make this code more efficient. For that, let's think a bit more about our goals: writing N files of more or less the same length.\n",
    "\n",
    "* How can we do that without counting the amount of blocs?\n",
    "* Is tehre a way to move in a file without reading every line?\n",
    "\n",
    "### TODO:\n",
    "\n",
    "* Open the file as bytes: https://docs.python.org/3/library/functions.html#open\n",
    "* Get the size of the file: https://docs.python.org/3/library/os.path.html#os.path.getsize)\n",
    "* Use `seek` to move in the file, `tell` to figure out where you are, and `read` to copy file chunks (https://docs.python.org/3/tutorial/inputoutput.html?highlight=tell%20file#methods-of-file-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def file_splitter(source_file_name, number_of_files, separator=b'\\n', output_name='split'):\n",
    "    source_file = Path(source_file_name)\n",
    "    if not isinstance(separator, bytes):\n",
    "        separator = separator.encode()\n",
    "    logging.debug('File size: {}.'.format(os.path.getsize(source_file)))\n",
    "    chunk_size = round(os.path.getsize(source_file) / number_of_files)\n",
    "    logging.debug('Chunk size per file: {}.'.format(chunk_size))\n",
    "    \n",
    "    with open(source_file, 'rb') as f:  # Required to open the file as bytes for seek\n",
    "        file_number = 0\n",
    "        current_position = 0\n",
    "        while True:\n",
    "            precedent_position = current_position\n",
    "            # Jump of \"size\" from the current place in the file\n",
    "            f.seek(chunk_size, os.SEEK_CUR)\n",
    "            s = f.readline()\n",
    "            while s and s != separator:\n",
    "                # find the next separator\n",
    "                s = f.readline()\n",
    "            # Get the current place\n",
    "            current_position = f.tell()\n",
    "            # Copy and write in the new file everything between precedent_position and current_position\n",
    "            with open(source_file, 'r') as temp:\n",
    "                temp.seek(precedent_position)\n",
    "                copy = temp.read(current_position - precedent_position)\n",
    "            logging.debug('Opening {}.'.format('{}_{}.txt'.format(output_name, file_number)))\n",
    "            with open('{}_{}.txt'.format(output_name, file_number), 'w') as new_f:\n",
    "                new_f.write(copy)\n",
    "                file_number += 1\n",
    "            if not s:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "\n",
    "Let's make it even better.\n",
    "\n",
    "### TODO\n",
    "\n",
    "* Only open the source file once\n",
    "* Use `pathlib.Path`: https://docs.python.org/3/library/pathlib.html#concrete-paths\n",
    "* Get the size of the file with `stat`: https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def file_splitter(source_file_name, number_of_files, separator=b'\\n', output_name='split'):\n",
    "    source_file = Path(source_file_name)\n",
    "    if not isinstance(separator, bytes):\n",
    "        separator = separator.encode()\n",
    "    logging.debug('File size: {}.'.format(source_file.stat().st_size))                                    \n",
    "    chunk_size = round(source_file.stat().st_size / number_of_files)\n",
    "    logging.debug('Chunk size per file: {}.'.format(chunk_size))\n",
    "    \n",
    "    with open(source_file, 'rb') as f:  # Required to open the file as bytes for seek\n",
    "        file_number = 0\n",
    "        while True:\n",
    "            # Jump of \"size\" from the current place in the file\n",
    "            to_write = f.read(chunk_size)\n",
    "            while True:\n",
    "                rest_of_line = f.readline()\n",
    "                to_write += rest_of_line\n",
    "                if not rest_of_line or rest_of_line == separator:\n",
    "                    break\n",
    "            logging.debug('Opening {}.'.format('{}_{}.txt'.format(output_name, file_number)))\n",
    "            with open('{}_{}.txt'.format(output_name, file_number), 'wb') as new_f:\n",
    "                new_f.write(to_write)\n",
    "                file_number += 1\n",
    "            if not rest_of_line:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "\n",
    "* Fetch new files when there is something available\n",
    "    * http://data.ris.ripe.net/rrc00/latest-bview.gz\n",
    "    * ===> http://docs.python-requests.org/en/master/api/#requests.head & Last-Modified\n",
    "\n",
    "* Use the library to generate text files:\n",
    "    * https://bitbucket.org/ripencc/bgpdump/downloads/ (Installation details: https://bitbucket.org/ripencc/bgpdump/wiki/Home.wiki#!building)\n",
    "\n",
    "    ```\n",
    "    sh ./bootstrap.sh\n",
    "    make\n",
    "    ./bgpdump -T\n",
    "    ```\n",
    "\n",
    "    ./bgpdump -O ../data/latest-bview.txt  ../data/original/latest-bview.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 ++\n",
    "\n",
    "\n",
    "If you're fast and bored:\n",
    "* Make it a class (with comments)\n",
    "* Yield pseudo files (`BytesIO`) instead of writing the files on the disk\n",
    "* Use `argparse` to make the script more flexible\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
