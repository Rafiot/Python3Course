{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting point: end of day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "def entries_counter(source_file):\n",
    "    matches = re.findall('^$', open(source_file, 'r').read(), flags=re.MULTILINE)\n",
    "    nb_blocks = len(matches)\n",
    "    logging.debug(f'{nb_blocks} blocks in the file \"{source_file}\".')\n",
    "    return nb_blocks\n",
    "\n",
    "def file_splitter(source_file_name, number_of_files, separator='\\n', output_name='split'):\n",
    "    logging.info(f'Start to split \"{source_file_name}\" in {number_of_files} files.')\n",
    "    total_blocs_in_file = entries_counter(source_file=source_file_name)\n",
    "    max_blocs_in_file = round(total_blocs_in_file/float(number_of_files), 0)\n",
    "    logging.debug(f'{max_blocs_in_file} blocks per file.')\n",
    "    \n",
    "    padding_length = len(str(number_of_files))\n",
    "    \n",
    "    with open(source_file_name, 'r') as original_file:\n",
    "        file_number = 1\n",
    "        blocs_in_file = 0\n",
    "        new_file_content = ''\n",
    "\n",
    "        # Loop through the file, line by line\n",
    "        for line in original_file:\n",
    "            # Store the line in a temporary variable\n",
    "            new_file_content += line\n",
    "            if line == separator:\n",
    "                # Count the blocks\n",
    "                blocs_in_file += 1\n",
    "            if blocs_in_file > max_blocs_in_file:\n",
    "                logging.debug(f'Writing {output_name}_{file_number:0{padding_length}}.txt.')\n",
    "                # If we reach the limit, write the content of the temporary variable in the new file\n",
    "                with open(f'{output_name}_{file_number:0{padding_length}}.txt', 'w') as new_file:\n",
    "                    new_file.write(new_file_content)\n",
    "                # Reset counters\n",
    "                file_number += 1\n",
    "                blocs_in_file = 0\n",
    "                new_file_content = ''\n",
    "        else:\n",
    "            logging.debug(f'Writing {output_name}_{file_number:0{padding_length}}.txt.')\n",
    "            # EOF reached, writing everything we have in the temporary variable\n",
    "            with open(f'{output_name}_{file_number:0{padding_length}}.txt', 'w') as new_file:\n",
    "                new_file.write(new_file_content)\n",
    "    logging.info(f'Done with \"{source_file_name}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=100, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "\n",
    "with open('data/bview.20030809.1600.txt', 'rb') as f:\n",
    "    hash_source = hashlib.sha256(f.read()).hexdigest()\n",
    "print(hash_source)\n",
    "\n",
    "hash_dest = hashlib.sha256()\n",
    "for out_file in sorted(glob.glob('split_*.txt')):\n",
    "    with open(out_file, 'rb') as f:\n",
    "        hash_dest.update(f.read())\n",
    "dest = hash_dest.hexdigest()\n",
    "print(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install line-profiler memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%prun file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%prun file_splitter(source_file_name='data/bview.20180216.0800.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit \n",
    "\n",
    "file_splitter(source_file_name='data/bview.20030809.1600.txt', number_of_files=10, separator='\\n', output_name='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1 - Complete rewrite! \n",
    "\n",
    "Let's think a bit how we can make this code more efficient. For that, let's think a bit more about our goals: writing N files of more or less the same length.\n",
    "\n",
    "* How can we do that without counting the amount of blocs?\n",
    "* Is there a way to move in a file without reading every line?\n",
    "\n",
    "### TODO:\n",
    "\n",
    "* Get the size of the file: https://docs.python.org/3/library/os.path.html#os.path.getsize)\n",
    "* Open the file as bytes: https://docs.python.org/3/library/functions.html#open\n",
    "* Use `seek` to move in the file, `tell` to figure out where you are, and `read` to copy file chunks (https://docs.python.org/3/tutorial/inputoutput.html?highlight=tell%20file#methods-of-file-objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Pythonize the rewrite\n",
    "\n",
    "\n",
    "Let's make it even better.\n",
    "\n",
    "### TODO\n",
    "\n",
    "* Only open the source file once\n",
    "* Use `pathlib.Path`: https://docs.python.org/3/library/pathlib.html#concrete-paths\n",
    "* Get the size of the file with `stat`: https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Make it a class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Write test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Python Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - More cool tweaks\n",
    "\n",
    "* Yield pseudo files (`BytesIO`) instead of writing the files on the disk\n",
    "* Use `argparse` to make the script easier to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 ++ - Integrate the module in something bigger\n",
    "\n",
    "\n",
    "If you're fast and bored:\n",
    "\n",
    "* Fetch new files when there is something available\n",
    "    * http://data.ris.ripe.net/rrc00/latest-bview.gz\n",
    "    * ===> http://docs.python-requests.org/en/master/api/#requests.head & Last-Modified\n",
    "\n",
    "* Use the library to generate text files:\n",
    "    * https://bitbucket.org/ripencc/bgpdump/downloads/ (Installation details: https://bitbucket.org/ripencc/bgpdump/wiki/Home.wiki#!building)\n",
    "\n",
    "    ```\n",
    "    sh ./bootstrap.sh\n",
    "    make\n",
    "    ./bgpdump -T\n",
    "    ```\n",
    "\n",
    "    ./bgpdump -O ../data/latest-bview.txt  ../data/original/latest-bview.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
